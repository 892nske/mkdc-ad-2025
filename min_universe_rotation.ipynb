{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 最小ユニバース：日本株×米株ETF×暗号資産のクラスタリング＆ローテーション\n",
        "\n",
        "- 生成日: 2025-11-06\n",
        "- このノートブックは、JP株（J-Quants）、米株ETF＆USDJPY（yfinance）、暗号資産（CCXT）を用いて、\n",
        "  **クラスタリング→クラスター・ローテーション**戦略を検証します。\n",
        "\n",
        "**構成**\n",
        "1. セットアップ（パッケージ導入・基本設定）\n",
        "2. データ取得（J-Quants / yfinance / CCXT）\n",
        "3. 特徴量作成（モメンタム/ボラ/DD/相関/β）\n",
        "4. クラスタリング（PCA→k-means）\n",
        "5. ローテーション・バックテスト（ウォークフォワード）\n",
        "6. 評価（Sharpe/最大DD など）＆可視化\n",
        "\n",
        "※ 学術・教育目的のサンプルです。実運用の前にデータの整合性・約定/コスト/税制などを必ず検証してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. セットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Versions:\n",
            "pandas 2.2.3\n",
            "numpy 2.2.3\n",
            "matplotlib 3.10.1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# %%capture\n",
        "# ランタイムにインストール（必要に応じてコメント解除）\n",
        "# !pip install pandas numpy matplotlib scikit-learn yfinance ccxt tqdm requests\n",
        "\n",
        "import os\n",
        "import math\n",
        "import json\n",
        "import time\n",
        "import uuid\n",
        "import warnings\n",
        "import datetime as dt\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import yfinance as yf\n",
        "import ccxt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"Versions:\")\n",
        "import pandas, numpy, sklearn, matplotlib\n",
        "print(\"pandas\", pandas.__version__)\n",
        "print(\"numpy\", numpy.__version__)\n",
        "print(\"matplotlib\", matplotlib.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 設定（ユニバース・期間・APIキーなど）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config loaded.\n",
            "Period: 2023-10-01 → 2025-08-31\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ---- 期間設定 ----\n",
        "START_DATE = \"2023-10-01\"\n",
        "END_DATE   = \"2025-08-31\"\n",
        "\n",
        "# ---- ユニバース（最小構成） ----\n",
        "# 日本株（J-Quantsの銘柄コードは4桁。市場別コードは不要）\n",
        "JP_TICKERS = {\n",
        "    \"7203\": \"TOYOTA\",\n",
        "    \"6758\": \"SONY\",\n",
        "}\n",
        "\n",
        "# 米国ETF（yfinanceのティッカー）\n",
        "US_ETF_TICKERS = {\n",
        "    \"SPY\": \"SP500 ETF\",\n",
        "    \"QQQ\": \"NASDAQ100 ETF\",\n",
        "}\n",
        "\n",
        "# 暗号資産（CCXT；取引所はBinanceのUSDT建てを利用）\n",
        "CRYPTO_SYMBOLS = {\n",
        "    \"BTC/USDT\": \"Bitcoin\",\n",
        "    \"ETH/USDT\": \"Ethereum\",\n",
        "}\n",
        "\n",
        "# 為替（yfinance）\n",
        "USDJPY_TICKER = \"USDJPY=X\"\n",
        "\n",
        "# ---- J-Quants API 認証情報 ----\n",
        "# J-Quantsリフレッシュトークンは.envファイルから読み込み\n",
        "load_dotenv()\n",
        "JQ_REFRESH_TOKEN = os.getenv(\"JQUANTS_REFRESH_TOKEN\")\n",
        "\n",
        "# ---- 出力フォルダ ----\n",
        "OUT_DIR = \"./output_min_universe\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Config loaded.\")\n",
        "print(\"Period:\", START_DATE, \"→\", END_DATE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. データ取得"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 J-Quants：日本株の終値を取得"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "JQ_BASE = \"https://api.jquants.com/v1\"\n",
        "\n",
        "def jq_get_id_token(refresh_token: str) -> str:\n",
        "    \"\"\"J-QuantsのリフレッシュトークンからIDトークンを取得\"\"\"\n",
        "    url = f\"{JQ_BASE}/token/auth_refresh?refreshtoken={refresh_token}\"\n",
        "    r = requests.post(url)\n",
        "    r.raise_for_status()\n",
        "    return r.json().get(\"idToken\")\n",
        "\n",
        "def jq_get_daily_quotes(id_token: str, code: str, from_date: str, to_date: str) -> pd.DataFrame:\n",
        "    \"\"\"銘柄コード（4桁）の日次株価（終値など）を取得\"\"\"\n",
        "    url = f\"{JQ_BASE}/prices/daily_quotes\"\n",
        "    headers = {\"Authorization\": f\"Bearer {id_token}\"}\n",
        "    params = {\"code\": code, \"from\": from_date, \"to\": to_date}\n",
        "    r = requests.get(url, headers=headers, params=params)\n",
        "    r.raise_for_status()\n",
        "    data = r.json().get(\"daily_quotes\", [])\n",
        "    if not data:\n",
        "        return pd.DataFrame()\n",
        "    df = pd.DataFrame(data)\n",
        "    # 'Date'列をindexに、終値は'Close'（仕様変更の可能性に注意）\n",
        "    # J-Quantsでは 'Close' ではなく 'ClosePrice' などの名称の場合があります。\n",
        "    # 取得結果のキー確認を推奨。\n",
        "    close_key = \"Close\" if \"Close\" in df.columns else (\"ClosePrice\" if \"ClosePrice\" in df.columns else None)\n",
        "    if close_key is None:\n",
        "        raise ValueError(\"J-Quantsのレスポンスに終値カラムが見つかりません。API仕様をご確認ください。\")\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "    df = df.set_index(\"Date\").sort_index()\n",
        "    return df[[close_key]].rename(columns={close_key: code})\n",
        "\n",
        "def load_japan_prices(codes: Dict[str, str], start: str, end: str) -> pd.DataFrame:\n",
        "    id_token = jq_get_id_token(JQ_REFRESH_TOKEN)\n",
        "    frames = []\n",
        "    for code in tqdm(codes.keys()):\n",
        "        df = jq_get_daily_quotes(id_token, code, start, end)\n",
        "        frames.append(df)\n",
        "        time.sleep(0.2)  # API呼び出し間隔\n",
        "    out = pd.concat(frames, axis=1)\n",
        "    out.index = pd.to_datetime(out.index).tz_localize(None)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 yfinance：米国ETFとUSDJPYを取得"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def load_yf_prices(tickers: List[str], start: str, end: str) -> pd.DataFrame:\n",
        "    data = yf.download(tickers, start=start, end=end, progress=False)[\"Adj Close\"]\n",
        "    if isinstance(data, pd.Series):\n",
        "        data = data.to_frame()\n",
        "    data.index = pd.to_datetime(data.index).tz_localize(None)\n",
        "    return data\n",
        "\n",
        "def load_usd_jpy(start: str, end: str) -> pd.Series:\n",
        "    s = load_yf_prices([USDJPY_TICKER], start, end)[USDJPY_TICKER]\n",
        "    s.name = \"USDJPY\"\n",
        "    return s\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 CCXT：暗号資産（Binance USDT建）を取得"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def load_ccxt_ohlcv(symbol: str, start: str, end: str, timeframe=\"1d\") -> pd.DataFrame:\n",
        "    ex = ccxt.binance()\n",
        "    since = int(pd.Timestamp(start, tz='UTC').timestamp() * 1000)\n",
        "    end_ms = int(pd.Timestamp(end, tz='UTC').timestamp() * 1000)\n",
        "    all_rows = []\n",
        "    while True:\n",
        "        ohlcvs = ex.fetch_ohlcv(symbol, timeframe=timeframe, since=since, limit=1000)\n",
        "        if not ohlcvs:\n",
        "            break\n",
        "        df = pd.DataFrame(ohlcvs, columns=[\"ts\",\"open\",\"high\",\"low\",\"close\",\"volume\"])\n",
        "        all_rows.append(df)\n",
        "        since = int(df[\"ts\"].iloc[-1]) + 24*60*60*1000\n",
        "        if since >= end_ms: break\n",
        "        time.sleep(0.2)\n",
        "    if not all_rows:\n",
        "        return pd.DataFrame()\n",
        "    out = pd.concat(all_rows, axis=0)\n",
        "    out[\"Date\"] = pd.to_datetime(out[\"ts\"], unit=\"ms\", utc=True).dt.tz_convert(None)\n",
        "    out = out.set_index(\"Date\").sort_index()\n",
        "    return out[[\"close\"]].rename(columns={\"close\": symbol})\n",
        "\n",
        "def load_crypto_prices(symbols: Dict[str, str], start: str, end: str) -> pd.DataFrame:\n",
        "    frames = []\n",
        "    for sym in tqdm(symbols.keys()):\n",
        "        df = load_ccxt_ohlcv(sym, start, end)\n",
        "        frames.append(df)\n",
        "    if not frames:\n",
        "        return pd.DataFrame()\n",
        "    out = pd.concat(frames, axis=1)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 前処理：JPY建て統一・カレンダー整形"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YF.download() has changed argument auto_adjust default to True\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'Adj Close'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py311/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyError\u001b[39m: 'Adj Close'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# --- 取得＆整形 ---\u001b[39;00m\n\u001b[32m     14\u001b[39m jp = load_japan_prices(JP_TICKERS, START_DATE, END_DATE)   \u001b[38;5;66;03m# JPY建て\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m us = \u001b[43mload_yf_prices\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mUS_ETF_TICKERS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTART_DATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEND_DATE\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# USD建て\u001b[39;00m\n\u001b[32m     16\u001b[39m usd_jpy = load_usd_jpy(START_DATE, END_DATE)\n\u001b[32m     17\u001b[39m crypto_usd = load_crypto_prices(CRYPTO_SYMBOLS, START_DATE, END_DATE)   \u001b[38;5;66;03m# USDT≒USD建てとみなす\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mload_yf_prices\u001b[39m\u001b[34m(tickers, start, end)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_yf_prices\u001b[39m(tickers: List[\u001b[38;5;28mstr\u001b[39m], start: \u001b[38;5;28mstr\u001b[39m, end: \u001b[38;5;28mstr\u001b[39m) -> pd.DataFrame:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     data = \u001b[43myf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAdj Close\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd.Series):\n\u001b[32m      4\u001b[39m         data = data.to_frame()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py311/lib/python3.11/site-packages/pandas/core/frame.py:4101\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4099\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[32m   4100\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m4101\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_multilevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4102\u001b[39m     indexer = \u001b[38;5;28mself\u001b[39m.columns.get_loc(key)\n\u001b[32m   4103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py311/lib/python3.11/site-packages/pandas/core/frame.py:4159\u001b[39m, in \u001b[36mDataFrame._getitem_multilevel\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4157\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_getitem_multilevel\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m   4158\u001b[39m     \u001b[38;5;66;03m# self.columns is a MultiIndex\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4159\u001b[39m     loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4160\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, (\u001b[38;5;28mslice\u001b[39m, np.ndarray)):\n\u001b[32m   4161\u001b[39m         new_columns = \u001b[38;5;28mself\u001b[39m.columns[loc]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py311/lib/python3.11/site-packages/pandas/core/indexes/multi.py:3040\u001b[39m, in \u001b[36mMultiIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3037\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mask\n\u001b[32m   3039\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m3040\u001b[39m     loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_level_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3041\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _maybe_to_slice(loc)\n\u001b[32m   3043\u001b[39m keylen = \u001b[38;5;28mlen\u001b[39m(key)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py311/lib/python3.11/site-packages/pandas/core/indexes/multi.py:3391\u001b[39m, in \u001b[36mMultiIndex._get_level_indexer\u001b[39m\u001b[34m(self, key, level, indexer)\u001b[39m\n\u001b[32m   3388\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(i, j, step)\n\u001b[32m   3390\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3391\u001b[39m     idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_loc_single_level_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3393\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m level > \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lexsort_depth == \u001b[32m0\u001b[39m:\n\u001b[32m   3394\u001b[39m         \u001b[38;5;66;03m# Desired level is not sorted\u001b[39;00m\n\u001b[32m   3395\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mslice\u001b[39m):\n\u001b[32m   3396\u001b[39m             \u001b[38;5;66;03m# test_get_loc_partial_timestamp_multiindex\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py311/lib/python3.11/site-packages/pandas/core/indexes/multi.py:2980\u001b[39m, in \u001b[36mMultiIndex._get_loc_single_level_index\u001b[39m\u001b[34m(self, level_index, key)\u001b[39m\n\u001b[32m   2978\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -\u001b[32m1\u001b[39m\n\u001b[32m   2979\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2980\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlevel_index\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/py311/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
            "\u001b[31mKeyError\u001b[39m: 'Adj Close'"
          ]
        }
      ],
      "source": [
        "\n",
        "def align_calendar(dfs: List[pd.DataFrame]) -> pd.DataFrame:\n",
        "    # 全インデックスのユニオン→昇順→前方埋め\n",
        "    idx = sorted(set().union(*[df.index for df in dfs if df is not None]))\n",
        "    out = pd.DataFrame(index=pd.to_datetime(idx))\n",
        "    for df in dfs:\n",
        "        out = out.join(df, how=\"left\")\n",
        "    out = out.sort_index().ffill()\n",
        "    return out\n",
        "\n",
        "def to_jpy(prices_usd: pd.DataFrame, usd_jpy: pd.Series) -> pd.DataFrame:\n",
        "    return prices_usd.mul(usd_jpy, axis=0)\n",
        "\n",
        "# --- 取得＆整形 ---\n",
        "jp = load_japan_prices(JP_TICKERS, START_DATE, END_DATE)   # JPY建て\n",
        "us = load_yf_prices(list(US_ETF_TICKERS.keys()), START_DATE, END_DATE)  # USD建て\n",
        "usd_jpy = load_usd_jpy(START_DATE, END_DATE)\n",
        "crypto_usd = load_crypto_prices(CRYPTO_SYMBOLS, START_DATE, END_DATE)   # USDT≒USD建てとみなす\n",
        "\n",
        "# JPYへ換算\n",
        "us_jpy = to_jpy(us, usd_jpy)\n",
        "crypto_jpy = to_jpy(crypto_usd, usd_jpy.reindex(crypto_usd.index).ffill())\n",
        "\n",
        "# カレンダー整合\n",
        "panel = align_calendar([jp, us_jpy, crypto_jpy])\n",
        "panel = panel.dropna(how=\"all\")\n",
        "panel.columns.name = \"Assets\"\n",
        "panel.tail()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 特徴量作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def pct_log(s: pd.Series) -> pd.Series:\n",
        "    return np.log(s).diff()\n",
        "\n",
        "def rolling_beta(y: pd.Series, x: pd.Series, window: int=252) -> pd.Series:\n",
        "    # 単回帰のβ（共分散/分散）\n",
        "    cov = y.rolling(window).cov(x)\n",
        "    var = x.rolling(window).var()\n",
        "    return cov / var\n",
        "\n",
        "def max_drawdown(series: pd.Series, window: int=252) -> pd.Series:\n",
        "    roll_max = series.rolling(window).max()\n",
        "    dd = series/roll_max - 1.0\n",
        "    return dd.rolling(window).min()\n",
        "\n",
        "def ewma_vol(returns: pd.Series, lam: float=0.94, window: int=63) -> pd.Series:\n",
        "    # 近似：通常のrollingで近似EWMAを作る（厳密なλはお好みで）\n",
        "    return returns.rolling(window).std() * np.sqrt(252)\n",
        "\n",
        "# ベンチシリーズ（SPY-JPY換算 & BTC-JPY換算の代理）\n",
        "bench_spy = us_jpy[\"SPY\"].reindex(panel.index).ffill()\n",
        "bench_btc = crypto_jpy.filter(like=\"BTC\").iloc[:,0].reindex(panel.index).ffill()\n",
        "\n",
        "rets = panel.apply(pct_log).fillna(0.0)\n",
        "\n",
        "features = {}\n",
        "for col in panel.columns:\n",
        "    price = panel[col]\n",
        "    r = rets[col]\n",
        "\n",
        "    mom63 = r.rolling(63).sum()\n",
        "    vol63 = ewma_vol(r, lam=0.94, window=63)\n",
        "    dd252 = max_drawdown(price, window=252)\n",
        "    corr_spy = r.rolling(63).corr(rets[bench_spy.name]) if bench_spy.name in rets.columns else r.rolling(63).corr(bench_spy.pct_change().fillna(0))\n",
        "    corr_btc = r.rolling(63).corr(rets[bench_btc.name]) if bench_btc.name in rets.columns else r.rolling(63).corr(bench_btc.pct_change().fillna(0))\n",
        "    beta_mkt = rolling_beta(r, rets[bench_spy.name] if bench_spy.name in rets.columns else bench_spy.pct_change().fillna(0), window=252)\n",
        "\n",
        "    df = pd.concat([mom63, vol63, dd252, corr_spy, corr_btc, beta_mkt], axis=1)\n",
        "    df.columns = pd.MultiIndex.from_product([[col], [\"momentum\",\"volatility\",\"drawdown\",\"corr_spy\",\"corr_btc\",\"beta_market\"]])\n",
        "    features[col] = df\n",
        "\n",
        "feat = pd.concat(features.values(), axis=1)\n",
        "feat = feat.dropna(how=\"all\")\n",
        "feat.tail()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. クラスタリング（月次で更新：PCA→k-means）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def prepare_matrix(feat: pd.DataFrame) -> pd.DataFrame:\n",
        "    # 列順：資産×特徴量で安定化\n",
        "    feat = feat.copy()\n",
        "    feat = feat.sort_index(axis=1, level=[0,1])\n",
        "    return feat\n",
        "\n",
        "def fit_cluster(X: pd.DataFrame, n_components: float=0.95, k: int=3):\n",
        "    scaler = RobustScaler()\n",
        "    Xs = scaler.fit_transform(X)\n",
        "    pca = PCA(n_components=n_components, random_state=42)\n",
        "    Z = pca.fit_transform(Xs)\n",
        "    km = KMeans(n_clusters=k, n_init=20, random_state=42)\n",
        "    labels = km.fit_predict(Z)\n",
        "    return scaler, pca, km, labels, Z\n",
        "\n",
        "def monthly_cluster_labels(feat: pd.DataFrame, start_month: str=None, k:int=3) -> pd.DataFrame:\n",
        "    featm = prepare_matrix(feat)\n",
        "    months = sorted({(d.year, d.month) for d in featm.index})\n",
        "    if start_month:\n",
        "        y, m = map(int, start_month.split(\"-\"))\n",
        "        months = [mm for mm in months if (mm[0]>y) or (mm[0]==y and mm[1]>=m)]\n",
        "    label_store = []\n",
        "\n",
        "    for (yy, mm) in tqdm(months):\n",
        "        end = pd.Timestamp(yy, mm, 1) - pd.offsets.Day(1)\n",
        "        if end < featm.index.min() + pd.offsets.Day(300):\n",
        "            continue\n",
        "        train = featm.loc[:end]\n",
        "        train = train.dropna()\n",
        "        if train.empty: \n",
        "            continue\n",
        "\n",
        "        scaler, pca, km, labels, Z = fit_cluster(train, k=k)\n",
        "\n",
        "        # その月の最終日までのラベルを推定（簡便化：直近のクラスタ中心で予測）\n",
        "        month_end = pd.Timestamp(yy, mm, 1) + pd.offsets.MonthEnd(0)\n",
        "        span = featm.loc[:month_end].tail(1).index  # その月の最終日\n",
        "        # 実運用では月内の毎営業日ラベルを推定してもOK\n",
        "        # ここでは月次更新の代表ラベルとして最終日だけ保存\n",
        "        lastX = train.tail(1)\n",
        "        Xs = scaler.transform(lastX)\n",
        "        Z = pca.transform(Xs)\n",
        "        lab = km.predict(Z)[0]\n",
        "        label_store.append(pd.DataFrame(\n",
        "            {\"date\":[month_end], \"cluster\":[lab]}\n",
        "        ).set_index(\"date\"))\n",
        "\n",
        "    labels_df = pd.concat(label_store).sort_index()\n",
        "    return labels_df\n",
        "\n",
        "# クラスタ数は3で開始\n",
        "labels_monthly = monthly_cluster_labels(feat, k=3)\n",
        "labels_monthly.tail()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. ローテーション（週次）：クラスター・スコアで配分"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def cluster_score(feat_slice: pd.DataFrame) -> pd.Series:\n",
        "    # クラスター平均のスコア： momentum - 0.5*volatility\n",
        "    # feat_slice: index=dates, columns=(asset, feature)\n",
        "    last = feat_slice.tail(1)\n",
        "    # 各資産のスコア\n",
        "    scores = {}\n",
        "    for asset in last.columns.get_level_values(0).unique():\n",
        "        mom = last[(asset, \"momentum\")].iloc[0]\n",
        "        vol = last[(asset, \"volatility\")].iloc[0]\n",
        "        s = mom - 0.5*(vol if not np.isnan(vol) else 0)\n",
        "        scores[asset] = s\n",
        "    return pd.Series(scores).sort_values(ascending=False)\n",
        "\n",
        "def backtest_rotation(panel: pd.DataFrame, feat: pd.DataFrame, labels_m: pd.DataFrame,\n",
        "                      rebalance=\"W-MON\", k:int=3, top_clusters:int=1,\n",
        "                      turnover_cap:float=0.10, fee_bps:float=10.0) -> pd.DataFrame:\n",
        "    prices = panel.copy()\n",
        "    rets = prices.apply(lambda s: np.log(s).diff()).fillna(0.0)\n",
        "\n",
        "    # シンプル化：各資産のクラスタは「最新の月次ラベル」を共通とみなす（最小ユニバースなので）\n",
        "    # 実際には各資産ごとにクラスタを推定する方が自然。ここでは教育的簡略版。\n",
        "    rb_dates = pd.date_range(rets.index.min(), rets.index.max(), freq=rebalance)\n",
        "    weights = pd.DataFrame(index=rb_dates, columns=prices.columns, data=0.0)\n",
        "\n",
        "    prev_w = pd.Series(0.0, index=prices.columns)\n",
        "\n",
        "    for d in tqdm(rb_dates):\n",
        "        # 直近の月末ラベル\n",
        "        lab_row = labels_m[labels_m.index<=d].tail(1)\n",
        "        if lab_row.empty:\n",
        "            continue\n",
        "        cluster_id = int(lab_row[\"cluster\"].iloc[0])\n",
        "\n",
        "        # クラスタ毎にスコア算出（ここでは全資産同一クラスタ扱い→上位n資産にする）\n",
        "        # 本来は資産ごとの属するクラスタでグルーピング→クラスター平均スコアで配分。\n",
        "        # 簡略：資産スコア上位 -> 均等配分\n",
        "        window = feat.loc[:d].tail(63)  # 3ヶ月分を参考\n",
        "        s = cluster_score(window)\n",
        "\n",
        "        selected = s.head(2).index  # 代表2銘柄に配分（均等）\n",
        "        w = pd.Series(0.0, index=prices.columns)\n",
        "        if len(selected)>0:\n",
        "            w[selected] = 1.0/len(selected)\n",
        "\n",
        "        # ターンオーバー制約（L1ノルムで近づける簡易版）\n",
        "        change = w - prev_w\n",
        "        if change.abs().sum() > turnover_cap:\n",
        "            # 比率で縮小\n",
        "            ratio = turnover_cap / change.abs().sum()\n",
        "            w = prev_w + change * ratio\n",
        "\n",
        "        weights.loc[d] = w.values\n",
        "        prev_w = w\n",
        "\n",
        "    # 日次リターンにリバランス重みを前方埋め\n",
        "    weights_daily = weights.reindex(rets.index).ffill().fillna(0.0)\n",
        "\n",
        "    # 取引コスト（リバランス日の重み変化に対してbps課金）\n",
        "    fee_series = pd.Series(0.0, index=rets.index)\n",
        "    rb_mask = weights_daily.index.isin(weights.index)\n",
        "    w_change = weights_daily.diff().fillna(0.0).abs().sum(axis=1)\n",
        "    fee_series[rb_mask] = (w_change[rb_mask] * (fee_bps/10000.0))\n",
        "\n",
        "    strat_ret = (weights_daily * rets).sum(axis=1) - fee_series\n",
        "    eq = strat_ret.cumsum().apply(np.exp)\n",
        "\n",
        "    out = pd.DataFrame({\"strategy\": strat_ret, \"equity\": eq})\n",
        "    return out\n",
        "\n",
        "bt = backtest_rotation(panel, feat, labels_monthly,\n",
        "                       rebalance=\"W-MON\", k=3, top_clusters=1,\n",
        "                       turnover_cap=0.10, fee_bps=10.0)\n",
        "bt.tail()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 評価指標"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def annualize_return(ret: pd.Series, freq: int=252) -> float:\n",
        "    mu = ret.mean()*freq\n",
        "    return mu\n",
        "\n",
        "def annualize_vol(ret: pd.Series, freq: int=252) -> float:\n",
        "    return ret.std()*np.sqrt(freq)\n",
        "\n",
        "def sharpe(ret: pd.Series, rf: float=0.0, freq: int=252) -> float:\n",
        "    mu = annualize_return(ret, freq) - rf\n",
        "    sd = annualize_vol(ret, freq)\n",
        "    return mu/sd if sd>0 else np.nan\n",
        "\n",
        "def max_dd_from_equity(eq: pd.Series) -> float:\n",
        "    roll_max = eq.cummax()\n",
        "    dd = eq/roll_max - 1.0\n",
        "    return dd.min()\n",
        "\n",
        "def summary_metrics(ret: pd.Series, name=\"strategy\") -> pd.Series:\n",
        "    eq = ret.cumsum().apply(np.exp)\n",
        "    return pd.Series({\n",
        "        \"CAGR(approx)\": annualize_return(ret),\n",
        "        \"Vol\": annualize_vol(ret),\n",
        "        \"Sharpe\": sharpe(ret),\n",
        "        \"MaxDD\": max_dd_from_equity(eq)\n",
        "    }, name=name)\n",
        "\n",
        "bench = pd.DataFrame({\n",
        "    \"SPY_JPY\": np.log(panel[\"SPY\"]).diff().fillna(0.0),\n",
        "    \"BTC_JPY\": np.log(panel.filter(like=\"BTC\").iloc[:,0]).diff().fillna(0.0),\n",
        "}).dropna()\n",
        "\n",
        "summ = pd.concat([\n",
        "    summary_metrics(bt[\"strategy\"], \"Strategy\"),\n",
        "    summary_metrics(bench[\"SPY_JPY\"], \"SPY_JPY\"),\n",
        "    summary_metrics(bench[\"BTC_JPY\"], \"BTC_JPY\"),\n",
        "], axis=1)\n",
        "summ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. 可視化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# エクイティカーブ\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(bt.index, bt[\"equity\"], label=\"Strategy\")\n",
        "if \"SPY\" in panel.columns:\n",
        "    spy_eq = np.log(panel[\"SPY\"]).diff().fillna(0).cumsum().apply(np.exp)\n",
        "    plt.plot(spy_eq.index, spy_eq, label=\"SPY (JPY)\")\n",
        "if panel.filter(like=\"BTC\").shape[1] > 0:\n",
        "    btc_col = panel.filter(like=\"BTC\").columns[0]\n",
        "    btc_eq = np.log(panel[btc_col]).diff().fillna(0).cumsum().apply(np.exp)\n",
        "    plt.plot(btc_eq.index, btc_eq, label=\"BTC (JPY)\")\n",
        "plt.legend()\n",
        "plt.title(\"Equity Curve (Strategy vs Benchmarks)\")\n",
        "plt.xlabel(\"Date\"); plt.ylabel(\"Growth (×)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. 注意点と次のステップ\n",
        "- **クラスタの当て方（資産ごとのラベル推定）**を簡略化しています。本番では、PCA後の各時点の各資産特徴ベクトルに対して、\n",
        "  学習済みクラスタへの所属（`km.predict`）を資産別に推定し、そのクラスター平均スコアで配分してください。\n",
        "- CCXTの取引所・シンボル、J-Quantsの終値カラム名は環境で異なる可能性があるため、**レスポンスのキーを確認**して調整してください。\n",
        "- 取引コスト、スリッページ、売買不可日（休日）などは単純化しています。必要に応じて厳密化してください。\n",
        "- 指標や可視化は最小限です。相関ヒートマップ、レーダーチャート、月次リターン表などを追加すると分析が深まります。\n",
        "- ユニバースを増やす場合は、ETFやJP銘柄を追加し、`features`の次元が増えた際は`n_components`の調整や正則化をご検討ください。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
